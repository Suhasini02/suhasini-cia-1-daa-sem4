{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64551914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 21.2.4 from C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\pip (python 3.9)\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45e51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c1ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e50d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=pd.read_csv('C:/Users/suhas/Downloads/archive (5)/Bank_Personal_Loan_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ef64bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b367bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a2f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "data.drop(['ID'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975922bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(['Personal Loan'],axis=1).values\n",
    "y=data['Personal Loan'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522008a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x , dtype = torch.float64)\n",
    "y = torch.tensor(y)\n",
    "y = y.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860535c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d83738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self,input_size,hidden1,hidden2,output_size):\n",
    "        super().__init__()\n",
    "        self.input_=nn.Linear(input_size,hidden1)\n",
    "        self.hidden1_=nn.Linear(hidden1,hidden2)\n",
    "        self.out=nn.Linear(hidden2,output_size)\n",
    "    def forward(self,x):\n",
    "        x=f.relu(self.input_(x))\n",
    "        x=torch.sigmoid(self.hidden1_(x))\n",
    "        x=self.out(x)\n",
    "        x=f.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fab29c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 12])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ec58678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(12 , 10 , 8 , 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289e2541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of NN(\n",
       "  (input_): Linear(in_features=12, out_features=10, bias=True)\n",
       "  (hidden1_): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (out): Linear(in_features=8, out_features=4, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e99c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a5c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8933b9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4228ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "import tensorflow as tf\n",
    "from   torch.optim.lr_scheduler import ExponentialLR as ExponentialLR\n",
    "#from torch.optim.lr_scheduler import ExponentialLR\n",
    "optimizer = torch.optim.Adam( model.parameters(), lr=100)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca81882",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1039ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(x , y)\n",
    "data = DataLoader(data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155e17e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 has loss of 1.393481969833374\n",
      "Epoch 10 has loss of 0.8396684527397156\n",
      "Epoch 20 has loss of 0.8396684527397156\n",
      "Epoch 30 has loss of 0.8396684527397156\n",
      "Epoch 40 has loss of 0.8396684527397156\n",
      "Epoch 50 has loss of 0.8396684527397156\n",
      "Epoch 60 has loss of 0.8396684527397156\n",
      "Epoch 70 has loss of 0.8396684527397156\n",
      "Epoch 80 has loss of 0.8396684527397156\n",
      "Epoch 90 has loss of 0.8396684527397156\n",
      "Epoch 100 has loss of 0.8396684527397156\n",
      "Epoch 110 has loss of 0.8396684527397156\n",
      "Epoch 120 has loss of 0.8396684527397156\n",
      "Epoch 130 has loss of 0.8396684527397156\n",
      "Epoch 140 has loss of 0.8396684527397156\n",
      "Epoch 150 has loss of 0.8396684527397156\n",
      "Epoch 160 has loss of 0.8396684527397156\n",
      "Epoch 170 has loss of 0.8396684527397156\n",
      "Epoch 180 has loss of 0.8396684527397156\n",
      "Epoch 190 has loss of 0.8396684527397156\n",
      "Epoch 200 has loss of 0.8396684527397156\n",
      "Epoch 210 has loss of 0.8396684527397156\n",
      "Epoch 220 has loss of 0.8396684527397156\n",
      "Epoch 230 has loss of 0.8396684527397156\n",
      "Epoch 240 has loss of 0.8396684527397156\n",
      "Epoch 250 has loss of 0.8396684527397156\n",
      "Epoch 260 has loss of 0.8396684527397156\n",
      "Epoch 270 has loss of 0.8396684527397156\n",
      "Epoch 280 has loss of 0.8396684527397156\n",
      "Epoch 290 has loss of 0.8396684527397156\n",
      "Epoch 300 has loss of 0.8396684527397156\n",
      "Epoch 310 has loss of 0.8396684527397156\n",
      "Epoch 320 has loss of 0.8396684527397156\n",
      "Epoch 330 has loss of 0.8396684527397156\n",
      "Epoch 340 has loss of 0.8396684527397156\n",
      "Epoch 350 has loss of 0.8396684527397156\n",
      "Epoch 360 has loss of 0.8396684527397156\n",
      "Epoch 370 has loss of 0.8396684527397156\n",
      "Epoch 380 has loss of 0.8396684527397156\n",
      "Epoch 390 has loss of 0.8396684527397156\n",
      "Epoch 400 has loss of 0.8396684527397156\n",
      "Epoch 410 has loss of 0.8396684527397156\n",
      "Epoch 420 has loss of 0.8396684527397156\n",
      "Epoch 430 has loss of 0.8396684527397156\n",
      "Epoch 440 has loss of 0.8396684527397156\n",
      "Epoch 450 has loss of 0.8396684527397156\n",
      "Epoch 460 has loss of 0.8396684527397156\n",
      "Epoch 470 has loss of 0.8396684527397156\n",
      "Epoch 480 has loss of 0.8396684527397156\n",
      "Epoch 490 has loss of 0.8396684527397156\n",
      "Epoch 500 has loss of 0.8396684527397156\n",
      "Epoch 510 has loss of 0.8396684527397156\n",
      "Epoch 520 has loss of 0.8396684527397156\n",
      "Epoch 530 has loss of 0.8396684527397156\n",
      "Epoch 540 has loss of 0.8396684527397156\n",
      "Epoch 550 has loss of 0.8396684527397156\n",
      "Epoch 560 has loss of 0.8396684527397156\n",
      "Epoch 570 has loss of 0.8396684527397156\n",
      "Epoch 580 has loss of 0.8396684527397156\n",
      "Epoch 590 has loss of 0.8396684527397156\n",
      "Epoch 600 has loss of 0.8396684527397156\n",
      "Epoch 610 has loss of 0.8396684527397156\n",
      "Epoch 620 has loss of 0.8396684527397156\n",
      "Epoch 630 has loss of 0.8396684527397156\n",
      "Epoch 640 has loss of 0.8396684527397156\n",
      "Epoch 650 has loss of 0.8396684527397156\n",
      "Epoch 660 has loss of 0.8396684527397156\n",
      "Epoch 670 has loss of 0.8396684527397156\n",
      "Epoch 680 has loss of 0.8396684527397156\n",
      "Epoch 690 has loss of 0.8396684527397156\n",
      "Epoch 700 has loss of 0.8396684527397156\n",
      "Epoch 710 has loss of 0.8396684527397156\n",
      "Epoch 720 has loss of 0.8396684527397156\n",
      "Epoch 730 has loss of 0.8396684527397156\n",
      "Epoch 740 has loss of 0.8396684527397156\n",
      "Epoch 750 has loss of 0.8396684527397156\n",
      "Epoch 760 has loss of 0.8396684527397156\n",
      "Epoch 770 has loss of 0.8396684527397156\n",
      "Epoch 780 has loss of 0.8396684527397156\n",
      "Epoch 790 has loss of 0.8396684527397156\n",
      "Epoch 800 has loss of 0.8396684527397156\n",
      "Epoch 810 has loss of 0.8396684527397156\n",
      "Epoch 820 has loss of 0.8396684527397156\n",
      "Epoch 830 has loss of 0.8396684527397156\n",
      "Epoch 840 has loss of 0.8396684527397156\n",
      "Epoch 850 has loss of 0.8396684527397156\n",
      "Epoch 860 has loss of 0.8396684527397156\n",
      "Epoch 870 has loss of 0.8396684527397156\n",
      "Epoch 880 has loss of 0.8396684527397156\n",
      "Epoch 890 has loss of 0.8396684527397156\n",
      "Epoch 900 has loss of 0.8396684527397156\n",
      "Epoch 910 has loss of 0.8396684527397156\n",
      "Epoch 920 has loss of 0.8396684527397156\n",
      "Epoch 930 has loss of 0.8396684527397156\n",
      "Epoch 940 has loss of 0.8396684527397156\n",
      "Epoch 950 has loss of 0.8396684527397156\n",
      "Epoch 960 has loss of 0.8396684527397156\n",
      "Epoch 970 has loss of 0.8396684527397156\n",
      "Epoch 980 has loss of 0.8396684527397156\n",
      "Epoch 990 has loss of 0.8396684527397156\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    final_losses = []\n",
    "    for i in range(n_epochs):\n",
    "        y_pred = model(x.float())\n",
    "        loss = loss_function(y_pred , y)\n",
    "        final_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if (i%10 == 0):\n",
    "            print(\"Epoch {} has loss of {}\".format(i , loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f22ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f7c324ca0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1 , n_epochs+1) , final_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f9ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i , data in enumerate(x):\n",
    "        y_pred = (model(data.float()))\n",
    "        predictions.append(y_pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf29878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9360e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4520\n",
      "           1       0.00      0.00      0.00       480\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.45      0.50      0.47      5000\n",
      "weighted avg       0.82      0.90      0.86      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60222db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2416bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95cc944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/suhas/Downloads/archive (5)/Bank_Personal_Loan_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a3ba547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a536a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   25           1      49     91107       4    1.6          1         0   \n",
       "1   45          19      34     90089       3    1.5          1         0   \n",
       "2   39          15      11     94720       1    1.0          1         0   \n",
       "3   35           9     100     94112       1    2.7          2         0   \n",
       "4   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27582514",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Personal Loan'] , axis = 1)\n",
    "y = df['Personal Loan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84f6924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2ec10fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dda1b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10 , input_shape=(12,)))\n",
    "model.add(tf.keras.layers.Dense(20))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dba7ce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "75/75 [==============================] - 1s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 2/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 3/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 4/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 5/500\n",
      "75/75 [==============================] - 0s 988us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 6/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 7/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 8/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 9/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 10/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 11/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 12/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 13/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 14/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 15/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 16/500\n",
      "75/75 [==============================] - 0s 983us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 17/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 18/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 19/500\n",
      "75/75 [==============================] - 0s 994us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 20/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 21/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 22/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 23/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 24/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 25/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 26/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 27/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 28/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 29/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 30/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 31/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 32/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 33/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 34/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 35/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 36/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 37/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 38/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 39/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 40/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 41/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 42/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 43/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 44/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 45/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 46/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 47/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 48/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 49/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 50/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 51/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 52/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 53/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 54/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 55/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 56/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 57/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 58/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 59/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 60/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 61/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 62/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 63/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 64/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 65/500\n",
      "75/75 [==============================] - 0s 994us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 66/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 67/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 68/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 69/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 70/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 71/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 72/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 73/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 74/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 75/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 76/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 77/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 78/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 79/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 80/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 81/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 82/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 83/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 84/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 85/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 86/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 87/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 88/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 89/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 90/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 91/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 92/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 93/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 94/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 95/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 96/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 97/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 98/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 99/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 100/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 101/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 102/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 103/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 104/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 105/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 106/500\n",
      "75/75 [==============================] - 0s 1000us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 107/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 108/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 109/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 110/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 111/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 112/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 113/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 114/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 115/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 116/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 117/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 118/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 119/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 120/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 121/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 122/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 123/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 124/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 125/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 126/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 127/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 128/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 129/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 130/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 131/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 132/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 133/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 134/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 135/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 136/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 137/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 138/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 139/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 140/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 141/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 142/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 143/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 144/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 145/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 146/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 147/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 148/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 149/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 150/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 151/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 152/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 153/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 154/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 155/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 156/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 157/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 158/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 159/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 160/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 161/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 162/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 163/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 164/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 165/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 166/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 167/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 168/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 169/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 170/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 171/500\n",
      "75/75 [==============================] - 0s 985us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 172/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 173/500\n",
      "75/75 [==============================] - 0s 992us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 174/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 175/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 176/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 177/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 178/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 179/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 180/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 181/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 182/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 183/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 184/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 185/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 186/500\n",
      "75/75 [==============================] - 0s 996us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 187/500\n",
      "75/75 [==============================] - 0s 981us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 188/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 189/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 190/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 191/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 192/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 193/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 194/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 195/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 196/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 197/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 198/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 199/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 200/500\n",
      "75/75 [==============================] - 0s 984us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 201/500\n",
      "75/75 [==============================] - 0s 986us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 202/500\n",
      "75/75 [==============================] - 0s 976us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 203/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 204/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 205/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 206/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 207/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 208/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 209/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 210/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 211/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 212/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 213/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 214/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 215/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 216/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 217/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 218/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 219/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 220/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 221/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 222/500\n",
      "75/75 [==============================] - 0s 995us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 223/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 224/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 225/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 226/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 227/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 228/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 229/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 230/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 231/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 232/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 233/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 234/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 235/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 236/500\n",
      "75/75 [==============================] - 0s 995us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 237/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 238/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 239/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 240/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 241/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 242/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 243/500\n",
      "75/75 [==============================] - 0s 970us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 244/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 245/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 246/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 247/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 248/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 249/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 250/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 251/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 252/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 253/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 254/500\n",
      "75/75 [==============================] - 0s 988us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 255/500\n",
      "75/75 [==============================] - 0s 982us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 256/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 257/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 258/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 259/500\n",
      "75/75 [==============================] - 0s 979us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 260/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 261/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 262/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 263/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 264/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 265/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 266/500\n",
      "75/75 [==============================] - 0s 998us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 267/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 268/500\n",
      "75/75 [==============================] - 0s 997us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 269/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 270/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 271/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 272/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 273/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 274/500\n",
      "75/75 [==============================] - 0s 974us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 275/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 276/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 277/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 278/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 279/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 280/500\n",
      "75/75 [==============================] - 0s 978us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 281/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 282/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 283/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 284/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 285/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 286/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 287/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 288/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 289/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 290/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 291/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 292/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 293/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 294/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 295/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 296/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 297/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 298/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 299/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 300/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 301/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 302/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 303/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 304/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 305/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 306/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 307/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 308/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 309/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 310/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 311/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 312/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 313/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 314/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 315/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 316/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 317/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 318/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 319/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 320/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 321/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 322/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 323/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 324/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 325/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 326/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 327/500\n",
      "75/75 [==============================] - 0s 997us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 328/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 329/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 330/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 331/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 332/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 333/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 334/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 335/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 336/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 337/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 338/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 339/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 340/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 341/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 342/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 343/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 344/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 345/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 346/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 347/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 348/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 349/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 350/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 351/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 352/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 353/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 354/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 355/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 356/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 357/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 358/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 359/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 360/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 361/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 362/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 363/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 364/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 365/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 366/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 367/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 368/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 369/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 370/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 371/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 372/500\n",
      "75/75 [==============================] - 0s 986us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 373/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 374/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 375/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 376/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 377/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 378/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 379/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 380/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 381/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 382/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 383/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 384/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 385/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 386/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 387/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 388/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 389/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 390/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 391/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 392/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 393/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 394/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 395/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 396/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 397/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 398/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 399/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 400/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 401/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 402/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 403/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 404/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 405/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 406/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 407/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 408/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 409/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 410/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 411/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 412/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 413/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 414/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 415/500\n",
      "75/75 [==============================] - 0s 1000us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 416/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 417/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 418/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 419/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 420/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 421/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 422/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 423/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 424/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 425/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 426/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 427/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 428/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 429/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 430/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 431/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 432/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 433/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 434/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 435/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 436/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 437/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 438/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 439/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 440/500\n",
      "75/75 [==============================] - 0s 994us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 441/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 442/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 443/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 444/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 445/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 446/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 447/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 448/500\n",
      "75/75 [==============================] - 0s 975us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 449/500\n",
      "75/75 [==============================] - 0s 991us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 450/500\n",
      "75/75 [==============================] - 0s 998us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 451/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 452/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 453/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 454/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 455/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 456/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 457/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 458/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 459/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 460/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 461/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 462/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 463/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 464/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 465/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 466/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 467/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 468/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 469/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 470/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 471/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 472/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 473/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 474/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 475/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 476/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 477/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 478/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 479/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 480/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 481/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 482/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 483/500\n",
      "75/75 [==============================] - 0s 999us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 484/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 485/500\n",
      "75/75 [==============================] - 0s 985us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 486/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 487/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 488/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 489/500\n",
      "75/75 [==============================] - 0s 968us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 490/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 491/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 492/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 493/500\n",
      "75/75 [==============================] - 0s 971us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 494/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 495/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 496/500\n",
      "75/75 [==============================] - 0s 972us/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 497/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 498/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 499/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n",
      "Epoch 500/500\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9077\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.compile(loss='mse', optimizer='Adam', metrics=['acc'])\n",
    "    model.fit(x_train, y_train ,batch_size = 50 ,  epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bead1a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7fbb2267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.], dtype=float32), array([0.], dtype=float32))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(min(y_pred) , max(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c17eedbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0., 1250.,    0.,    0.,    0.,\n",
       "           0.]),\n",
       " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5],\n",
       "       dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d13eea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpy = y_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dbc2b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cpy>0.334).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2c75111a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90919d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501    0\n",
       "2586    1\n",
       "2653    0\n",
       "1055    0\n",
       "705     0\n",
       "       ..\n",
       "4141    0\n",
       "3168    0\n",
       "2478    0\n",
       "4214    0\n",
       "4180    0\n",
       "Name: Personal Loan, Length: 1250, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a9da370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1116\n",
      "           1       0.00      0.00      0.00       134\n",
      "\n",
      "    accuracy                           0.89      1250\n",
      "   macro avg       0.45      0.50      0.47      1250\n",
      "weighted avg       0.80      0.89      0.84      1250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\suhas\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65a916df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 10)                130       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e5b863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best position: [8.562844752057282e-05, -3.7980334559302434e-05]\n",
      "Best error: 8.774736838020036e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.PSO at 0x19e58a72550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, x0):\n",
    "        self.position_i = []\n",
    "        self.velocity_i = []\n",
    "        self.pos_best_i = []\n",
    "        self.err_best_i = -1\n",
    "        self.err_i = -1\n",
    "        \n",
    "        for i in range(0, num_dimensions):\n",
    "            self.velocity_i.append(random.uniform(-1, 1))\n",
    "            self.position_i.append(x0[i])\n",
    "    \n",
    "    def evaluate(self, costFunc):\n",
    "        self.err_i = costFunc(self.position_i)\n",
    "        \n",
    "        if self.err_i < self.err_best_i or self.err_best_i == -1:\n",
    "            self.pos_best_i = self.position_i\n",
    "            self.err_best_i = self.err_i\n",
    "    \n",
    "    def update_velocity(self, pos_best_g):\n",
    "        w = 0.5\n",
    "        c1 = 1\n",
    "        c2 = 2\n",
    "        \n",
    "        for i in range(0, num_dimensions):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            vel_cognitive = c1 * r1 * (self.pos_best_i[i] - self.position_i[i])\n",
    "            vel_social = c2 * r2 * (pos_best_g[i] - self.position_i[i])\n",
    "            self.velocity_i[i] = w * self.velocity_i[i] + vel_cognitive + vel_social\n",
    "    \n",
    "    def update_position(self, bounds):\n",
    "        for i in range(0, num_dimensions):\n",
    "            self.position_i[i] = self.position_i[i] + self.velocity_i[i]\n",
    "            \n",
    "            if self.position_i[i] > bounds[i][1]:\n",
    "                self.position_i[i] = bounds[i][1]\n",
    "            \n",
    "            if self.position_i[i] < bounds[i][0]:\n",
    "                self.position_i[i] = bounds[i][0]\n",
    "\n",
    "class PSO():\n",
    "    def __init__(self, costFunc, x0, bounds, num_particles, maxiter):\n",
    "        global num_dimensions\n",
    "        \n",
    "        num_dimensions = len(x0)\n",
    "        err_best_g = -1\n",
    "        pos_best_g = []\n",
    "        swarm = []\n",
    "        \n",
    "        for i in range(0, num_particles):\n",
    "            swarm.append(Particle(x0))\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < maxiter:\n",
    "            for j in range(0, num_particles):\n",
    "                swarm[j].evaluate(costFunc)\n",
    "                \n",
    "                if swarm[j].err_i < err_best_g or err_best_g == -1:\n",
    "                    pos_best_g = list(swarm[j].position_i)\n",
    "                    err_best_g = float(swarm[j].err_i)\n",
    "            \n",
    "            for j in range(0, num_particles):\n",
    "                swarm[j].update_velocity(pos_best_g)\n",
    "                swarm[j].update_position(bounds)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        print('Best position:', pos_best_g)\n",
    "        print('Best error:', err_best_g)\n",
    "\n",
    "# Example usage\n",
    "def sphere(x):\n",
    "    return sum([xi**2 for xi in x])\n",
    "\n",
    "bounds = [(-4.12, 5.12)] * 2\n",
    "PSO(sphere, [0.2, 0.3], bounds, num_particles=10, maxiter=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82a174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
